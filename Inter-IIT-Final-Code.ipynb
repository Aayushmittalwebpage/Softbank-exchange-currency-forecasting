{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's read all data (text and numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape:  (4176, 362) (4176,) (4176,)\n",
      "Test Shape:  (1000, 362) (1000,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Read word count data\n",
    "fp = open(\"../data/text_count.csv\")\n",
    "lines = fp.readlines()\n",
    "unique_words = dict()\n",
    "for line in lines:\n",
    "    line = line.strip().split(',')\n",
    "    unique_words[line[0]] = [np.log(float(line[1]))]\n",
    "    \n",
    "    \n",
    "# Read pre-processed text data\n",
    "fp = open(\"../data/text_pre-processed.csv\")\n",
    "lines = fp.readlines()\n",
    "docs = dict()\n",
    "for index, line in enumerate(lines):\n",
    "    line = line.strip().split(',')\n",
    "    docs[line[0]] = line[1:]\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "\n",
    "# Training data\n",
    "fp = open(\"../data/train_pruned.csv\")\n",
    "lines = fp.readlines()[1:]\n",
    "X_train, X_train_text, Y, span_train = list(), list(), list(), list()\n",
    "fp.close()\n",
    "\n",
    "for index, line in enumerate(lines):\n",
    "    line = line.strip().split(',')\n",
    "    row = list()\n",
    "    counter = 0\n",
    "    for i in line[3:]:\n",
    "        if len(i) < 1:\n",
    "            row.append(-999)\n",
    "            counter+=1\n",
    "        else:\n",
    "            row.append(float(i))\n",
    "    id_ = line[0]\n",
    "    tmp = float(line[2])\n",
    "    Y.append(tmp)\n",
    "    span_train.append(float(line[1]))\n",
    "    X_train.append([sigmoid(span_train[-1])]+row+unique_words.get(line[0], [0.0]))\n",
    "    X_train_text.append(docs.get(line[0], ['0']))\n",
    "\n",
    "X_train, Y, span_train = np.array(X_train), np.array(Y), np.array(span_train)\n",
    "print(\"Training Shape: \", X_train.shape, Y.shape, span_train.shape)\n",
    "\n",
    "\n",
    "# Testing data\n",
    "fp = open(\"../data/test.csv\")\n",
    "lines = fp.readlines()[1:]\n",
    "X_test, X_test_text, ids, span_test = list(), list(), list(), list()\n",
    "fp.close()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip().split(',')\n",
    "    row = list()\n",
    "    counter = 0\n",
    "    for i in line[2:]:\n",
    "        if len(i) < 1:\n",
    "            row.append(-999)\n",
    "            counter+=1\n",
    "        else:\n",
    "            row.append(float(i))\n",
    "    ids.append(line[0])\n",
    "    span_test.append(float(line[1]))\n",
    "    X_test.append([sigmoid(span_test[-1])]+row+unique_words.get(line[0], [0.0]))\n",
    "    X_test_text.append(docs.get(line[0], ['0']))\n",
    "                        \n",
    "\n",
    "X_test, span_test = np.array(X_test), np.array(span_test)\n",
    "print(\"Test Shape: \", X_test.shape, span_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we will compute weighted average of the best features with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Feature_type0\n",
    "x_train = np.concatenate((X_train[:,:61], X_train[:,-1:]), axis=1)\n",
    "x_test = np.concatenate((X_test[:,:61], X_test[:,-1:]), axis=1)\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_jobs=-1)\n",
    "x_train_k = kmeans.fit_transform(x_train)\n",
    "x_test_k = kmeans.transform(x_test)\n",
    "\n",
    "model = LGBMRegressor(max_depth=7, learning_rate=0.01, n_estimators=600, missing=-999)\n",
    "model.fit(np.concatenate((x_train, x_train_k), axis=1), Y)\n",
    "preds_type0 = model.predict(np.concatenate((x_test, x_test_k), axis=1))\n",
    "\n",
    "# Feature_type1\n",
    "x_train = np.concatenate((X_train[:,:1], X_train[:,61:121]), axis=1)\n",
    "x_test = np.concatenate((X_test[:,:1], X_test[:,61:121]), axis=1)\n",
    "\n",
    "model = LGBMRegressor(max_depth=6, learning_rate=0.01, n_estimators=556, missing=-999)\n",
    "model.fit(x_train, Y)\n",
    "preds_type1 = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Feature_type5\n",
    "x_train = np.concatenate((X_train[:,:1], X_train[:,301:]), axis=1)\n",
    "x_test = np.concatenate((X_test[:,:1], X_test[:,301:]), axis=1)\n",
    "\n",
    "model = LGBMRegressor(max_depth=6, learning_rate=0.01, n_estimators=556, missing=-999)\n",
    "model.fit(x_train, Y)\n",
    "preds_type5 = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Final weighting\n",
    "preds_weighted = list()\n",
    "for a, b, c in zip(preds_type0, preds_type1, preds_type5):\n",
    "    preds_weighted.append((a*0.15)+(b*0.75)+(c*0.1))\n",
    "\n",
    "submit_array = np.array([[i, j] for i, j in zip(ids, preds_weighted)])\n",
    "submit_array = np.insert(submit_array, -1, np.char.lower(submit_array[:,0]), axis=1)\n",
    "submit_array = submit_array[submit_array[:,1].argsort()[::-1]]\n",
    "submit_array = np.delete(submit_array, -2, axis=1)\n",
    "\n",
    "# Finally, write out the data\n",
    "fp = open(\"../data/submit.csv\", \"w\")\n",
    "fp.write(\"id,target\\n\")\n",
    "for i, j in submit_array:\n",
    "    fp.write(i+\",\"+j+\"\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally we will compute weighted average of previous weighted average with another LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape:  (965, 361) (965,) (965,)\n",
      "Test Shape:  (230, 361) (230,)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "\n",
    "# Training data\n",
    "fp = open(\"../data/train_pruned.csv\")\n",
    "lines = fp.readlines()[1:]\n",
    "X_train, Y, span_train = list(), list(), list()\n",
    "fp.close()\n",
    "\n",
    "for index, line in enumerate(lines):\n",
    "    line = line.strip().split(',')\n",
    "    row = list()\n",
    "    counter = 0\n",
    "    for i in line[3:]:\n",
    "        if len(i) < 1:\n",
    "            row.append(np.nan)\n",
    "            counter+=1\n",
    "        else:\n",
    "            row.append(float(i))\n",
    "    id_ = line[0]\n",
    "    if float(line[1]) <= 7:\n",
    "        span_train.append(float(line[1]))\n",
    "        Y.append(float(line[2]))\n",
    "        X_train.append([sigmoid(span_train[-1])]+row)\n",
    "\n",
    "X_train, Y, span_train = np.array(X_train), np.array(Y), np.array(span_train)\n",
    "print(\"Training Shape: \", X_train.shape, Y.shape, span_train.shape)\n",
    "\n",
    "\n",
    "# Testing data\n",
    "fp = open(\"../data/test.csv\")\n",
    "lines = fp.readlines()[1:]\n",
    "X_test, ids_small, span_test = list(), list(), list()\n",
    "fp.close()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip().split(',')\n",
    "    row = list()\n",
    "    counter = 0\n",
    "    for i in line[2:]:\n",
    "        if len(i) < 1:\n",
    "            row.append(np.nan)\n",
    "            counter+=1\n",
    "        else:\n",
    "            row.append(float(i))\n",
    "    if float(line[1]) <= 7:\n",
    "        span_test.append(float(line[1]))\n",
    "        ids_small.append(line[0])\n",
    "        X_test.append([sigmoid(span_test[-1])]+row)\n",
    "                        \n",
    "\n",
    "X_test, span_test = np.array(X_test), np.array(span_test)\n",
    "print(\"Test Shape: \", X_test.shape, span_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 1, 1, 4, 1, 6, 6, 5, 6, 5, 5, 4, 6, 8, 5, 4, 1, 5, 1, 8, 5,\n",
       "       8, 6, 4, 2, 1, 5, 2, 1, 5, 1, 1, 5, 4, 2, 6, 5, 1, 5, 2, 1, 8, 5,\n",
       "       6, 4, 8, 6, 1, 5, 6, 4, 6, 5, 2, 6, 5, 5, 8, 1, 4, 8, 2, 8, 1, 0,\n",
       "       8, 6, 2, 5, 8, 2, 2, 1, 4, 4, 5, 8, 8, 0, 2, 8, 4, 2, 5, 8, 8, 6,\n",
       "       2, 1, 8, 6, 7, 4, 6, 8, 4, 8, 6, 2, 2, 2, 6, 5, 2, 2, 8, 2, 5, 2,\n",
       "       6, 6, 5, 2, 6, 8, 8, 4, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "transformations = np.zeros((X_train.shape[1], 9))\n",
    "for i in range(X_train.shape[1]):\n",
    "    transformations[i,0] = abs(np.corrcoef(X_train[:,i], Y)[0,1])\n",
    "    transformations[i,1] = abs(np.corrcoef(np.sin(X_train[:,i]), Y)[0,1])\n",
    "    transformations[i,2] = abs(np.corrcoef(np.cos(X_train[:,i]), Y)[0,1])\n",
    "    transformations[i,3] = abs(np.corrcoef(1/(1 + np.exp(-X_train[:,i])), Y)[0,1])\n",
    "    transformations[i,4] = abs(np.corrcoef(np.power(X_train[:,i], 2), Y)[0,1])\n",
    "    transformations[i,5] = abs(np.corrcoef(np.power(X_train[:,i], 3), Y)[0,1])\n",
    "    transformations[i,6] = abs(np.corrcoef(np.power(X_train[:,i], 4), Y)[0,1])\n",
    "    transformations[i,7] = abs(np.corrcoef(x_train[:,i], Y)[0,1])\n",
    "    transformations[i,8] = abs(np.corrcoef(np.log(np.absolute(X_train[:,i])-np.mean(X_train[:,i])+1), Y)[0,1])\n",
    "\n",
    "ind_trans = np.argmax(transformations, axis=1)\n",
    "ind_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple(X):\n",
    "    return X\n",
    "\n",
    "def sin(X):\n",
    "    return np.sin(X)\n",
    "\n",
    "def cos(X):\n",
    "    return np.cos(X)\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1 + np.exp(-X))\n",
    "\n",
    "def square(X):\n",
    "    return np.power(X, 2)\n",
    "\n",
    "def cube(X):\n",
    "    return np.power(X, 3)\n",
    "\n",
    "def four(X):\n",
    "    return np.power(X, 4)\n",
    "\n",
    "def log_trans(X):\n",
    "    return np.log(np.absolute(X)-np.mean(X)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    if ind_trans[i] == 0:\n",
    "        X_train[:,i] = simple(X_train[:,i])\n",
    "        X_test[:,i] = simple(X_test[:,i])\n",
    "    elif ind_trans[i] == 1:\n",
    "        X_train[:,i] = sin(X_train[:,i])\n",
    "        X_test[:,i] = sin(X_test[:,i])\n",
    "    elif ind_trans[i] == 2:\n",
    "        X_train[:,i] = cos(X_train[:,i])\n",
    "        X_test[:,i] = cos(X_test[:,i])\n",
    "    elif ind_trans[i] == 3:\n",
    "        X_train[:,i] = sigmoid(X_train[:,i])\n",
    "        X_test[:,i] = sigmoid(X_test[:,i])\n",
    "    elif ind_trans[i] == 4:\n",
    "        X_train[:,i] = square(X_train[:,i])\n",
    "        X_test[:,i] = square(X_test[:,i])\n",
    "    elif ind_trans[i] == 5:\n",
    "        X_train[:,i] = cube(X_train[:,i])\n",
    "        X_test[:,i] = cube(X_test[:,i])\n",
    "    elif ind_trans[i] == 6:\n",
    "        X_train[:,i] = four(X_train[:,i])\n",
    "        X_test[:,i] = four(X_test[:,i])\n",
    "    elif ind_trans[i] == 7:\n",
    "        X_train[:,i] = x_train[:,i]\n",
    "        X_test[:,i] = x_test[:,i]\n",
    "    elif ind_trans[i] == 8:\n",
    "        X_train[:,i] = log_trans(X_train[:,i])\n",
    "        X_test[:,i] = log_trans(X_test[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature_type1\n",
    "model = LGBMRegressor(max_depth=3, learning_rate=0.01, n_estimators=600, max_bin=1000, num_leaves=1000, missing=-999)\n",
    "model.fit(X_train, Y)\n",
    "preds_small = model.predict(X_test)\n",
    "\n",
    "new_preds = list()\n",
    "for i in range(len(ids)):\n",
    "    if ids[i] in ids_small:\n",
    "        preds_weighted[i] = (preds_weighted[i]*0.5) + (preds_small[ids_small.index(ids[i])]*0.5)\n",
    "\n",
    "submit_array = np.array([[i, j] for i, j in zip(ids, preds_weighted)])\n",
    "submit_array = np.insert(submit_array, -1, np.char.lower(submit_array[:,0]), axis=1)\n",
    "submit_array = submit_array[submit_array[:,1].argsort()[::-1]]\n",
    "submit_array = np.delete(submit_array, -2, axis=1)\n",
    "\n",
    "# Finally, write out the data\n",
    "fp = open(\"../data/final_submit.csv\", \"w\")\n",
    "fp.write(\"id,target\\n\")\n",
    "for i, j in submit_array:\n",
    "    fp.write(i+\",\"+j+\"\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
